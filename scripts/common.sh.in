#!/bin/bash -eu

#
# Copyright (c) 2017, Carnegie Mellon University.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
# 1. Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
# 3. Neither the name of the University nor the names of its contributors
#    may be used to endorse or promote products derived from this software
#    without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT
# HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
# OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED
# AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY
# WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#


#
# global variables we set/use:
#  $dfsu_prefix - deltafs umbrella prefix directory (abspath)
#  $common_noinit - set to non-null disable call to common_init (for dbg)
#  $ip_subnet - the ip subnet we want to use (x.y.z.t)
#  $jobdir - per-job shared output directory (abspath)
#  $logfile - log shared by all exp runs (abspath)
#  $exp_logfile - log used by one specific exp run (abspath)
#  $nodes - number of nodes for vpic (int)
#  $bbos_buddies - number of nodes for bbos (int)
#  $cores - total cores across all nodes (int)
#  $all_nodes - list of all nodes (string - sep: comma)
#  $num_all_nodes - number of nodes in all_nodes (int)
#  $vpic_nodes - list of nodes for vpic (string - sep: comma)
#  $num_vpic_nodes - number of nodes in vpic_nodes (int)
#  $bbos_nodes - list of nodes for bbos (string - sep: comma)
#  $num_bbos_nodes - number of nodes in bbos_nodes (int)
#  $bb_log_size - BBOS max per-core log size in bytes
#  $vpic_epochs - number of frames/epochs for VPIC runs (int)
#  $vpic_steps - number of time steps for VPIC runs (int)
#  $do_querying - whether we will perform particle queries (bool - 0 or 1)
#

# environment variables we set/use:
#  $JOBDIRHOME - where to put job dirs (default: $HOME/jobs)
#                example: /lustre/ttscratch1/users/$USER
#  $JOBENV - operating env (one of moab, slurm, openmpi, or mpich)
#            we'll try and figure it out if not provided by user
#  $JOBRUNCMD - aprun/srun/mpirun command to use, should match $JOBENV
#               (only used if JOBENV is set by user)
#  $EXTRA_MPIOPTS - additional options that need to be passed to mpirun
#  $DW_SESSION_OVERRIDE - (cray) override the datawarp sessionid (for dbg)
#

#
# environment variables we use as input:
#  $HOME - your home directory
#  $DW_JOB_STRIPED - data wrap mount (cray)
#
#  Cray env running moab:
#    $MOAB_JOBNAME - jobname
#    $PBS_JOBID - job id
#    $PBS_NODEFILE - file with list of all nodes
#
#  Cray env running slurm:
#    $SLURM_JOB_NAME - jobname
#    $SLURM_JOBID - job id
#    $SLURM_JOB_NODELIST - list of all nodes
#       XXX: this node list is in compact form, we need to expand it
#            to get a full list of nodes.  there is a helper perl script
#            called "generate_pbs_nodefile" that will do this for us
#

#
# files we create:
#  $jobdir/hosts.txt - list of hosts
#  $jobdir/bbos.hosts - host file only of bbos hosts
#  $jobdir/vpic.hosts - host file only of vpic hosts
#

# TODO:
# - Convert node lists to ranges on CRAY

#
# prefix directory comes from cmake's ${CMAKE_INSTALL_PREFIX} variable
#
dfsu_prefix=@CMAKE_INSTALL_PREFIX@

### ensure definition of a set of global vars ###

#
# number of frames/epochs for VPIC runs
# default: 8
#
vpic_epochs=${vpic_epochs:-8}

#
# number of time steps for VPIC runs
# default: 1000
#
vpic_steps=${vpic_steps:-1000}

#
# job-wise log - shared among all exp runs
# default: null (XXX: but we override this in get_jobdir)
#
logfile=${logfile-}

#
# exp-wise log - one per exp run
# default: null
#
exp_logfile=${exp_logfile-}

#
# num of bbos nodes to use
# default: 0
#
bbos_buddies=${bbos_buddies:-0}

#
# if a read phase should follow a write phase
# default: 0
#
do_querying=${do_querying:-0}

#
# common_init: init the common.sh layer (mainly detecting env)
# uses/sets: $JOBENV, $JOBRUNCMD
#
common_init() {

  if [ x${JOBENV-} = x ]; then
    # try and guess our job environment
    export JOBRUNCMD=""            # only allowed through if JOBENV set by usr
    if [ x${PBS_JOBID-} != x ]; then
      export JOBENV=moab
    elif [ x${SLURM_JOBID-} != x ]; then
      export JOBENV=slurm
    elif [ `which mpirun.mpich` ]; then
      export JOBENV=mpich
    elif [ `which mpirun.openmpi` ]; then
      export JOBENV=openmpi
    else
      die "common.sh UNABLE TO DETERMINE ENV - ABORTING"
    fi
  else
    # verify user selected something we know about
    if [ $JOBENV != moab -a $JOBENV != slurm -a \
         $JOBENV != mpich -a $JOBENV != openmpi ]; then
      die "bad JOBENV ($JOBENV) provided by user - ABORTING"
    fi
  fi

  # set JOBRUNCMD to the default if not provided by user
  if [ x${JOBRUNCMD-} = x ]; then
    if [ $JOBENV = moab ]; then
      export JOBRUNCMD=aprun
    elif [ $JOBENV = slurm ]; then
      export JOBRUNCMD=srun
    elif [ $JOBENV = mpich ]; then
      export JOBRUNCMD=mpirun.mpich
    elif [ $JOBENV = openmpi ]; then
      export JOBRUNCMD=mpirun.openmpi
    fi
  fi

  message "-INFO- common_init: JOBENV=$JOBENV, JOBRUNCMD=$JOBRUNCMD"

  # verify cray env is set as expected
  if [ $JOBENV = moab ]; then
    if [ x${PBS_JOBID-} = x -o x${MOAB_JOBNAME-} = x \
         -o ! -f "$PBS_NODEFILE" ]; then
      die "bad moab setup - check jobname and nodefile"
    fi
  elif [ $JOBENV = slurm ]; then
    if [ x${SLURM_JOBID-} = x -o x${SLURM_JOB_NAME-} = x -o \
         x${SLURM_JOB_NODELIST-} = x ]; then
      die "bad slurm setup - check jobname and nodelist"
    fi
    if [ ! `which generate_pbs_nodefile` ]; then
      die "slurm helper script generate_pbs_nodefile not found in path"
    fi
  fi
}

#
# message: echo message to stdout, cc it to a default job-wise log file, and
# then cc it again to a specific exp-wise log file.
# note that if either $logfile or $exp_logfile is empty, tee will
# just print the message without writing to files
# uses: $logfile, $exp_logfile
#
message () { echo "$@" | tee -a $exp_logfile | tee -a $logfile; }

#
# die: emit a mesage and exit 1
#
die () { message "!!! ERROR !!! $@"; exit 1; }

#
# jobdir  ## Lustre
#
# get_jobdir: setup $jobdir var and makes sure $jobdir is present
# uses: $JOBENV, $MOAB_JOBNAME, $PBS_JOBID,
#       $SLURM_JOB_NAME, $SLURM_JOBID, $JOBDIRHOME
# sets: $jobdir  (XXX: also $logfile)
#
get_jobdir() {
    if [ x${JOBDIRHOME-} != x ]; then
        jobdirhome=${JOBDIRHOME}
    else
        jobdirhome=${HOME}/jobs
    fi

    if [ $JOBENV = moab ]; then
        jobdir=${jobdirhome}/${MOAB_JOBNAME}.${PBS_JOBID}
    elif [ $JOBENV = slurm ]; then
        jobdir=${jobdirhome}/${SLURM_JOB_NAME}.${SLURM_JOBID}
    elif [ x${MPIJOBNAME-} != x ]; then
        jobdir=${jobdirhome}/${MPIJOBNAME}.${MPIJOBID-$$}
    else
        jobdir=${jobdirhome}/`basename $0`.$$  # use top-level script name $0
    fi

    message "-INFO- creating jobdir..."
    mkdir -p ${jobdir} || die "cannot make jobdir ${jobdir}"
    message "-INFO- jobdir = ${jobdir}"

    # XXX: override default and auto set logfile
    logfile=${jobdir}/$(basename $jobdir).log
}

#
# bbdir  ## shared XFS on CN only
#
# get_bbdir: setup $bbdir var and makes sure $bbdir is present, otherwise
# falls back to $jobdir if BB is not available.  note that the
# $DW_JOB_STRIPED directory is only present on the compute nodes, so we
# must cycle through do_mpirun to access it...
# uses: $DW_JOB_STRIPED, $DW_SESSION_OVERRIDE, $jobdir
# sets: $bbdir
#
get_bbdir() {
    if [ x${DW_JOB_STRIPED-} = x ]; then
      bbdir=${jobdir}
      message "!!! WARNING !!! missing DW_JOB_STRIPED"
      message "!!! WARNING !!! putting bbdir data in jobdir for this test"
    else

      ### XXXCDC: previous version
      ###dwsessid=$(dwcli ls session)
      ###dwconfid=$(dwcli ls configuration)
      ###message "-INFO- >>> dwsessid=$dwsessid | dwconfid=$dwconfid"

      # new version from brad:
      # XXX: no error/sanity check on dwcli output
      if [ x${DW_SESSION_OVERRIDE-} = x ]; then
          # XXX: assume token is encoded in the dir path
          # (at least on slurm the token is the job id)
          dwtoken=$(basename $DW_JOB_STRIPED | cut -f 1 -d _)
          dwsessid=$(dwstat sessions | \
                     awk -v token=$dwtoken '{if ($3 == token) print $1}')
      else
          dwsessid=$DW_SESSION_OVERRIDE
      fi
      dwinstid=$(dwstat instances | \
                 awk -v sess=$dwsessid '{if ($3 == sess) print $1}')
      dwconfid=$(dwstat configurations | \
                 awk -v inst=$dwinstid '{if ($3 == inst) print $1}')

      message "-INFO- >>> dw ids sess/inst/conf=$dwsessid/$dwinstid/$dwconfid"

      jobdir_last_component=$(basename $jobdir)
      bbdir="${DW_JOB_STRIPED}/$jobdir_last_component"
      message "-INFO- creating bbdir..."
      do_mpirun 1 1 "" "" "mkdir -p ${bbdir}"
      do_mpirun 1 1 "" "" "ls ${bbdir}"
      message "-INFO- bbdir = ${bbdir}"
    fi
}

#
# bb_stageoutwait: wait for a stageout to complete
# uses: $dwsessid, $dwconfid
#
bb_stageoutwait() {
    status=""
    count=0
    while [ "$status" != "-" -a $count -lt 100 ]; do
        sleep 30
        dwcli stage query --session $dwsessid --configuration $dwconfid
        status=$(dwcli stage query --session $dwsessid \
                 --configuration $dwconfid | tail -2 | head -1 | \
                 awk '{ print $8 }')
        count=$((count++))
        echo "Files remaining to be staged: <$status>"
    done

    message "Stage Out Completed" "Status $status" "Count $count"
}

#
# all_nodes
#
# gen_hostfile: generate a list of hosts we have in $jobdir/hosts.txt
# one host per line.
# uses: $JOBENV, $PBS_NODEFILE
#       $SLURMJOB_NODELIST/generate_pbs_nodefile, $jobdir
# sets: $all_nodes, $num_all_nodes
# creates: $jobdir/hosts.txt
#
gen_hostfile() {
    message "-INFO- generating hostfile ${jobdir}/hosts.txt..."

    if [ $JOBENV = moab ]; then

        # Generate hostfile on CRAY and store on disk
        cat $PBS_NODEFILE | uniq | sort > $jobdir/hosts.txt || \
            die "failed to create hosts.txt file"

    elif [ $JOBENV = slurm ]; then

        # Generate hostfile on CRAY and store on disk
        tmp_nodefile=`generate_pbs_nodefile`
        cat $tmp_nodefile | uniq | sort > $jobdir/hosts.txt || \
            die "failed to create hosts.txt file"
        rm -f $tmp_nodefile

    else

        # Generate hostfile on Emulab and store on disk
        exp_hosts="`/share/testbed/bin/emulab-listall | tr ',' '\n'`"

        echo "$exp_hosts" > $jobdir/hosts.txt || \
            die "failed to create hosts.txt file"
    fi

    # Populate a variable with hosts
    all_nodes=$(cat ${jobdir}/hosts.txt)
    num_all_nodes=$(cat ${jobdir}/hosts.txt | tr ',' '\n' | sort | wc -l)
    message "-INFO- num hosts = ${num_all_nodes}"
}

#
# generate host list files: $jobdir/vpic.hosts, $jobdir/bbos.hosts
# uses: $jobdir, $nodes, $bbos_buddies
# sets: $vpic_nodes, $bbos_nodes
# creates: $jobdir/vpic.hosts, $jobdir/bbos.hosts
#
gen_hosts() {
    message "-INFO- generating vpic/bbos host lists..."

    # XXX: sanity check: # of nodes in list from PBS_NODEFILE or
    # XXX:               emulab-listall >= $nodes+$bbos_buddies

    # first generate the generic hosts.txt
    gen_hostfile

    # divide hosts.txt into parts based on $nodes and $bbos_nodes
    cat $jobdir/hosts.txt | head -n $nodes | \
        tr '\n' ',' | sed '$s/,$//' > $jobdir/vpic.hosts || \
        die "failed to create vpic.hosts file"
    cat $jobdir/hosts.txt | tail -n $bbos_buddies | \
        tr '\n' ',' | sed '$s/,$//' > $jobdir/bbos.hosts || \
        die "failed to create bbos.hosts file"

    ### set host list variables ###

    vpic_nodes=$(cat ${jobdir}/vpic.hosts)
    num_vpic_nodes=$(cat ${jobdir}/vpic.hosts | tr ',' '\n' | sort | wc -l)
    message "-INFO- num vpic nodes = ${num_vpic_nodes}"

    bbos_nodes=$(cat ${jobdir}/bbos.hosts)
    num_bbos_nodes=$(cat ${jobdir}/bbos.hosts | tr ',' '\n' | sort | wc -l)
    message "-INFO- num bbos nodes = ${num_bbos_nodes}"
}

#
# clear_caches: clear node caches on vpic nodes
# uses: $JOBENV, $vpic_nodes, $cores, $nodes
#
clear_caches() {
    message "-INFO- clearing node caches..."

    if [ $JOBENV = moab -o $JOBENV = slurm ]; then
        message "!!! WARNING !!! skipping cache clear ... no cray sudo access"
        #aprun -L $vpic_nodes -n $cores -N $nodes sudo sh -c \
        #    'echo 3 > /proc/sys/vm/drop_caches'
    else
        # this does more than just $vpic_nodes (does them all)
        # but that isn't really a problem...
        /share/testbed/bin/emulab-mpirunall sudo sh -c \
            'echo 3 > /proc/sys/vm/drop_caches'
    fi

    message "-INFO- done"
}

#
# do_mpirun: Run CRAY MPICH, ANL MPICH, or OpenMPI run command
#
# Arguments:
# @1 number of processes
# @2 number of processes per node
# @3 array of env vars: ("name1", "val1", "name2", ... )
# @4 host list (comma-separated)
# @5 executable (and any options that don't fit elsewhere)
# @6 extra_opts: extra options to mpiexec (optional)
# @7 log1: primary log file for mpi stdout (optional)
# @8 log2: secondary log file for mpi stdout (optional)
do_mpirun() {
    procs=$1
    ppnode=$2
    if [ ! -z "$3" ]; then
        declare -a envs=("${!3}")
    else
        envs=()
    fi
    hosts="$4"
    exe="$5"
    ### extra options to mpiexec ###
    extra_opts=${6-}
    ### log files ###
    log1=${7-$logfile}
    log2=${8-$exp_logfile}

    envstr=""; npstr=""; hstr=""

    if [ $JOBENV = moab ]; then

        # CRAY running moab....  we need to use aprun
        if [ ${#envs[@]} -gt 0 ]; then
            envstr=`printf -- "-e %s=%s " ${envs[@]}`
        fi

        if [ $ppnode -gt 0 ]; then
            npstr="-N $ppnode"
        fi

        if [ ! -z "$hosts" ]; then
            hstr="-L $hosts"
        fi

        message "[MPIEXEC]" "aprun -n $procs" $npstr $hstr $envstr \
                $extra_opts ${DEFAULT_MPIOPTS-} $exe
        aprun -n $procs $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe 2>&1 | \
            tee -a $log2 | tee -a $log1

    elif [ $JOBENV = slurm ]; then

        # CRAY running slurm....  we need to use srun
        if [ ${#envs[@]} -gt 0 ]; then
            envstr=`printf -- "%s=%s," ${envs[@]}`
            # XXX: "ALL" isn't documented in srun(1) man page, but it works.
            # without it, all other env vars are removed (e.g. as described
            # in the sbatch(1) man page ...).
            envstr="--export=${envstr}ALL"
        fi

        if [ $ppnode -gt 0 ]; then
            nnodes=$(( procs / ppnode ))
            npstr="-N $nnodes --ntasks-per-node=$ppnode"
        fi

        if [ ! -z "$hosts" ]; then
            hstr="-w $hosts"
        fi

        message "[MPIEXEC]" "srun -n $procs" $npstr $hstr $envstr \
            $extra_opts ${DEFAULT_MPIOPTS-} $exe
        srun -n $procs $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe 2>&1 | \
            tee -a $log2 | tee -a $log1

    elif [ $JOBENV = mpich ]; then

        if [ ${#envs[@]} -gt 0 ]; then
            envstr=`printf -- "-env %s %s " ${envs[@]}`
        fi

        if [ $ppnode -gt 0 ]; then
            npstr="-ppn $ppnode"
        fi

        if [ ! -z "$hosts" ]; then
            hstr="--host $hosts"
        fi

        message "[MPIEXEC]" "mpirun.mpich -np $procs" $npstr $hstr $envstr \
            $extra_opts ${DEFAULT_MPIOPTS-} $exe
        mpirun.mpich -np $procs $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe 2>&1 | \
            tee -a $log2 | tee -a $log1

    elif [ $JOBENV = openmpi ]; then

        if [ ${#envs[@]} -gt 0 ]; then
            envstr=`printf -- "-x %s=%s " ${envs[@]}`
        fi

        if [ $ppnode -gt 0 ]; then
            npstr="-npernode $ppnode"
        fi

        if [ ! -z "$hosts" ]; then
            if [ $ppnode -gt 1 ]; then
                hhstr="`printf '&,%.0s' $(seq 1 $(($ppnode-1)))`"
                hhstr="`echo $hosts | sed -e 's/\([^,]*\)/'"$hhstr&"'/g'`"
                hstr="--host $hhstr"
            else
                hstr="--host $hosts"
            fi
        fi

        message "[MPIEXEC]" "mpirun.openmpi -n $procs" $npstr $hstr $envstr \
            $extra_opts ${DEFAULT_MPIOPTS-} $exe
        mpirun.openmpi -n $procs $npstr $hstr $envstr $extra_opts \
            ${DEFAULT_MPIOPTS-} $exe 2>&1 | \
            tee -a $log2 | tee -a $log1

    else

        die "could not find a supported mpirun or aprun command"

    fi
}

#
# build_deck: build a vpic deck by copying the deck template to the jobdir,
# adjusting config.h, and then compiling it using the vpic-build.op script.
# the result is placed in $jobdir/current-deck.op (XXX: assume you are only
# going to have one compiled deck at a time).
#
# uses: $dfsu_prefix, $jobdir, $cores
# creates: $jobdir/current-deck.op
#
# Arguments:
# @1 in {"file-per-process", "file-per-particle"}
# @2 particles on x dimension
# @3 particles on y dimension
# @4 particles on z dimension
#
build_deck() {
    px=$2
    py=$3
    pz=$4

    ddir=${jobdir}/tmpdeck.$$     # tmp staging area for stacking the deck
    rm -rf ${ddir}
    cp -r ${dfsu_prefix}/decks ${ddir}
    mv ${ddir}/trecon-part/config.h ${ddir}/trecon-part/config.bkp || \
        die "mv failed"

    message "--------------- [INPUT-DECK] --------------"
    message "!!! NOTICE !!! building vpic deck >> $1 >> cores = ${cores}, px = ${px}, py = ${py}, pz = ${pz}"
    message ""

    case $1 in
    "file-per-process")
        cat ${ddir}/trecon-part/config.bkp | \
            sed 's/#define VPIC_TIMESTEPS.*/#define VPIC_TIMESTEPS '$vpic_steps'/' | \
            sed 's/#define VPIC_DUMPS.*/#define VPIC_DUMPS '$vpic_epochs'/' | \
            sed 's/^#define VPIC_FILE_PER_PARTICLE/\/\/#define VPIC_FILE_PER_PARTICLE/' | \
            sed 's/VPIC_TOPOLOGY_Y.*/VPIC_TOPOLOGY_Y 1/' | \
            sed 's/VPIC_TOPOLOGY_X.*/VPIC_TOPOLOGY_X '$cores'/' | \
            sed 's/VPIC_TOPOLOGY_Z.*/VPIC_TOPOLOGY_Z 1/' | \
            sed 's/VPIC_PARTICLE_X.*/VPIC_PARTICLE_X '$px'/' | \
            sed 's/VPIC_PARTICLE_Y.*/VPIC_PARTICLE_Y '$py'/' | \
            sed 's/VPIC_PARTICLE_Z.*/VPIC_PARTICLE_Z '$pz'/' >  \
                   ${ddir}/trecon-part/config.h || \
            die "config.h editing failed"
        ;;
    "file-per-particle")
        cat ${ddir}/trecon-part/config.bkp | \
            sed 's/#define VPIC_TIMESTEPS.*/#define VPIC_TIMESTEPS '$vpic_steps'/' | \
            sed 's/#define VPIC_DUMPS.*/#define VPIC_DUMPS '$vpic_epochs'/' | \
            sed 's/^\/\/#define VPIC_FILE_PER_PARTICLE/#define VPIC_FILE_PER_PARTICLE/' | \
            sed 's/VPIC_TOPOLOGY_Y.*/VPIC_TOPOLOGY_Y 1/' | \
            sed 's/VPIC_TOPOLOGY_X.*/VPIC_TOPOLOGY_X '$cores'/' | \
            sed 's/VPIC_TOPOLOGY_Z.*/VPIC_TOPOLOGY_Z 1/' | \
            sed 's/VPIC_PARTICLE_X.*/VPIC_PARTICLE_X '$px'/' | \
            sed 's/VPIC_PARTICLE_Y.*/VPIC_PARTICLE_Y '$py'/' | \
            sed 's/VPIC_PARTICLE_Z.*/VPIC_PARTICLE_Z '$pz'/' >  \
                   ${ddir}/trecon-part/config.h || \
            die "config.h editing failed"
        ;;
    *)
        die "build_deck: VPIC mode not supported"
        ;;
    esac

    # Compile input deck
    (cd ${ddir}/trecon-part && ${dfsu_prefix}/bin/vpic-build.op ./turbulence.cxx \
       2>&1 | tee -a $exp_logfile | tee -a $logfile) || \
           die "compilation failed"

    mv ${ddir}/trecon-part/turbulence.op ${jobdir}/current-deck.op || \
        die "install new current deck failed"

    message ""
    message "[DECK] --- $(ls -lni --full-time ${jobdir}/current-deck.op)"
    message ""

    message "-INFO- vpic deck installed at ${jobdir}/current-deck.op"
    message "--------------- [    OK    ] --------------"

    # don't need staging area anymore
    rm -rf ${ddir}
}

#
# do_run: run a vpic experiment
#
# uses: $dfsu_prefix, $jobdir, $bbdir, $cores, $nodes, $logfile, $vpic_nodes,
#        $bb_log_size, $bbos_buddies
#        $jobdir/current-deck.op (precompiled deck)
#        $jobdir/bbos.hosts, $jobdir/vpic.hosts
# creates: an experiment tag: {runtype}_P{particles}_C${cores}_N${nodes}
#          $bbdir/$exp_tag - primary output directory for the experiment
#          $jobdir/$exp_tag - secondary output directory for the experiment
#          $jobdir/$exp_tag/$exp_tag.log - logfile for the experiment
# side effects: changes current directory to $jobdir/$exp_tag
#
# Arguments:
# @1 experiment type in {"baseline", "deltafs", "shuffle_test"}
# @2 number of particles
# @3 ppn
do_run() {
    runtype=$1
    p=$2
    ppn=${3:-0}

    # pp: make a more human readable version of "p"
    if [ $((p / (10**6))) -gt 0 ]; then
        pp="$((p / (10**6)))M"
    elif [ $((p / (10**3))) -gt 0 ]; then
        pp="$((p / (10**3)))K"
    else
        pp="$p"
    fi

    exp_tag="${runtype}_P${pp}_C${cores}_N${nodes}"
    cd $jobdir || die "cd to $jobdir failed"
    exp_jobdir="$jobdir/$exp_tag"   ### NOTE !! still on Lustre !! ###
    mkdir -p $exp_jobdir || die "mkdir $exp_jobdir failed"
    mkdir -p $exp_jobdir/exp-info || die "mkdir $exp_jobdir/exp-info failed"
    cd $exp_jobdir || die "cd to $exp_jobdir failed"
    ### log file for this exp ###
    exp_logfile="$exp_jobdir/$exp_tag.log"   ### NOTE !! absolute path !! ###

    message "--------------- [   DOIT   ] --------------"
    message "!!! NOTICE !!! starting exp >> >> ${exp_tag}..."
    message ""

    ### ATTENTION: data might go to bb ###
    exp_dir="$bbdir/$exp_tag"
    message "-INFO- creating exp dir..."
    do_mpirun 1 1 "" "" "mkdir -p ${exp_dir}"
    message "-INFO- done"

    ### NOTE: cannot cd to $exp_dir since it may land in bb ###

    clear_caches

    message ""
    message "[DECK] --- $(ls -lni --full-time ${jobdir}/current-deck.op)"
    message ""

    ### SPAM ENOUGH TO MAKE BOSS HAPPY ###
    message "=================================================================="
    message "!!! Running VPIC ($runtype) with $pp particles on $cores cores and $nodes nodes !!!"
    message "------------"
    message "> Using ${jobdir}/current-deck.op"
    message "> Job dir is ${jobdir}"
    message "> Experiment dir is ${exp_dir}"
    message "> Log to ${exp_logfile}"
    message "  (+) Log to ${logfile}"
    message "      (+) Log to STDOUT"
    message "=================================================================="
    message ""

    case $runtype in
    "baseline")
        vpic_dir=$exp_dir/vpic

        ### BOOTSTRAPING ###
        message "-INFO- creating more exp dirs..."
        do_mpirun 1 1 "" "" "mkdir -p $vpic_dir"
        message "-INFO- done"

        ### WRITE PATH ###
        env_vars=(
            "VPIC_current_working_dir" "${vpic_dir}"
            "LD_PRELOAD" "${dfsu_prefix}/lib/libdeltafs-preload.so"
            "PRELOAD_Ignore_dirs" ${XX_IGNORE_DIRS:-":"}
            "PRELOAD_Log_home" "${exp_jobdir}/exp-info"
            "PRELOAD_No_sys_probing" ${XX_NO_SCAN:-"0"}
            "PRELOAD_Enable_verbose_error" ${XX_VERBOSE:-"1"}
        )

        do_mpirun $cores $ppn env_vars[@] "$vpic_nodes" "${jobdir}/current-deck.op" \
            "${EXTRA_MPIOPTS-}"

        message ""
        message "-INFO- checking output size..."
        do_mpirun 1 1 "" "" "du -sb $vpic_dir/particle" | tee -a $exp_jobdir/outsize.txt
        echo "Output size:" `cat $exp_jobdir/outsize.txt | \
            grep -F -v "[MPIEXEC]" | head -1 | cut -f1` "bytes" | \
                tee -a $exp_logfile | tee -a $logfile
        do_mpirun 1 1 "" "" "du -h $vpic_dir/particle"
        message "-INFO- done"

        ### STAGE DATA OUT ###
        if [ x$jobdir != x$bbdir ]; then
            message "-INFO- staging data out... "
            mkdir -p $exp_jobdir/bb || die "mkdir $exp_jobdir/bb failed"
            message ""
            message "FROM : $exp_dir" ### BB ###
            message "  TO : $exp_jobdir/bb"  ### Luster ###
            message ""

            message "[DWCLI] dwcli" "stage out" "--session $dwsessid" "--configuration $dwconfid" \
                "--backing-path $exp_jobdir/bb/" "--dir ${exp_dir:${#DW_JOB_STRIPED}}"
            dwcli stage out --session $dwsessid --configuration $dwconfid \
              --backing-path $exp_jobdir/bb/ --dir ${exp_dir:${#DW_JOB_STRIPED}}

            bb_stageoutwait

            message "-INFO- done"

            exp_dir=$exp_jobdir/bb
            vpic_dir=$exp_dir/vpic
        fi

        ### READ PATH ###
        if [ $do_querying -ne 0 ]; then
            query_particles $runtype $vpic_dir $pp
        fi
        ;;

    *)
        plfs_dir=$exp_dir/plfs
        vpic_dir=$exp_dir/vpic

        ### BOOTSTRAPING ###
        message "-INFO- creating more exp dirs..."
        do_mpirun 1 1 "" "" "mkdir -p $plfs_dir/particle"
        do_mpirun 1 1 "" "" "mkdir -p $vpic_dir"
        message "-INFO- done"

        ### WRITE PATH ###
        env_vars=(
            "VPIC_current_working_dir" "${vpic_dir}"
            "LD_PRELOAD" "${dfsu_prefix}/lib/libdeltafs-preload.so"
            "PRELOAD_Ignore_dirs" ${XX_IGNORE_DIRS:-":"}
            "PRELOAD_Deltafs_mntp" "particle"
            "PRELOAD_Local_root" "${plfs_dir}"
            "PRELOAD_Log_home" "${exp_jobdir}/exp-info"
            "PRELOAD_Bypass_deltafs_namespace" "1"
            "PRELOAD_Bypass_shuffle" ${XX_BYPASS_SHUFFLE:-"0"}
            "PRELOAD_Bypass_write" ${XX_BYPASS_WRITE:-"0"}
            "PRELOAD_Bypass_placement" ${XX_BYPASS_CH:-"0"}
            "PRELOAD_Skip_mon" ${XX_SKIP_MON:-"0"}
            "PRELOAD_Skip_sampling" ${XX_SKIP_SMP:-"1"}
            "PRELOAD_Sample_threshold" ${XX_SMP_TH:-"64"}
            "PRELOAD_No_sys_probing" ${XX_NO_SCAN:-"0"}
            "PRELOAD_No_paranoid_checks" ${XX_NO_CHECKS:-"1"}
            "PRELOAD_No_paranoid_barrier" ${XX_NO_BR:-"1"}
            "PRELOAD_No_paranoid_post_barrier" ${XX_NO_POST_BR:-"0"}
            "PRELOAD_No_paranoid_pre_barrier" ${XX_NO_PRE_BR:-"1"}
            "PRELOAD_No_epoch_pre_flushing" ${XX_NO_PRE_FLUSH:-"0"}
            "PRELOAD_Enable_verbose_error" ${XX_VERBOSE:-"1"}
            "SHUFFLE_Mercury_proto" ${XX_HG_PROTO:-"bmi+tcp"}
            "SHUFFLE_Mercury_progress_timeout" ${XX_HG_TIMEOUT:-"100"}
            "SHUFFLE_Mercury_progress_warn_interval" ${XX_HG_INTERVAL:-"200"}
            "SHUFFLE_Mercury_cache_handles" ${XX_HG_CACHE_HDL:-"0"}
            "SHUFFLE_Buffer_per_queue" ${XX_RPC_BUF:-"32768"}
            "SHUFFLE_Num_outstanding_rpc" ${XX_RPC_DEPTH:-"16"}
            "SHUFFLE_Use_worker_thread" ${XX_RPC_USE_WORKER:-"1"}
            "SHUFFLE_Force_rpc" ${XX_RPC_SELF_FORWARD:-"0"}
            "SHUFFLE_Force_sync_rpc" ${XX_RPC_FORCE_SYNC:-"0"}
            "SHUFFLE_Placement_protocol" ${XX_CH_PROTO:-"ring"}
            "SHUFFLE_Virtual_factor" ${XX_CH_VF:-"1024"}
            "SHUFFLE_Subnet" "${ip_subnet}"
            "SHUFFLE_Buf_localq" ${XX_SH_LBUFTGT:-"4096"}
            "SHUFFLE_Max_locals" ${XX_SH_LMAXRPC:-"8"}
            "SHUFFLE_Buf_remoteq" ${XX_SH_RBUFTGT:-"32768"}
            "SHUFFLE_Max_remotes" ${XX_SH_RMAXRPC:-"16"}
            "SHUFFLE_Max_deliverq" ${XX_SH_DMAX:-"256"}
            "SHUFFLE_Use_xn" ${XX_SH_THREE_HOP:-"1"}
            "PLFSDIR_Skip_checksums" ${XX_SKIP_CRC:-"1"}
            "PLFSDIR_Memtable_size" ${XX_MEMTABLE_SIZE:-"48MiB"}
            "PLFSDIR_Compaction_buf_size" ${XX_COMP_BUF:-"4MiB"}
            "PLFSDIR_Data_min_write_size" ${XX_MIN_DATA_BUF:-"6MiB"}
            "PLFSDIR_Data_buf_size" ${XX_MAX_DATA_BUF:-"8MiB"}
            "PLFSDIR_Index_min_write_size" ${XX_MIN_INDEX_BUF:-"2MiB"}
            "PLFSDIR_Index_buf_size" ${XX_MAX_INDEX_BUF:-"2MiB"}
            "PLFSDIR_Key_size" ${XX_KEY_SIZE:-"8"}
            "PLFSDIR_Filter_bits_per_key" ${XX_BF_BITS:-"14"}
            "PLFSDIR_Lg_parts" ${XX_LG_PARTS:-"2"}
        )

        do_mpirun $cores $ppn env_vars[@] "$vpic_nodes" "${jobdir}/current-deck.op" \
            "${EXTRA_MPIOPTS-}"

        message ""
        message "-INFO- checking output size..."
        do_mpirun 1 1 "" "" "du -sb $plfs_dir/particle" | tee -a $exp_jobdir/outsize.txt
        echo "Output size:" `cat $exp_jobdir/outsize.txt | \
            grep -F -v "[MPIEXEC]" | head -1 | cut -f1` "bytes" | \
                tee -a $exp_logfile | tee -a $logfile
        do_mpirun 1 1 "" "" "du -h $plfs_dir/particle"
        message "-INFO- done"

        ### STAGE DATA OUT ###
        if [ x$jobdir != x$bbdir ]; then
            message "-INFO- staging data out... "
            mkdir -p $exp_jobdir/bb || die "mkdir $exp_jobdir/bb failed"
            message ""
            message "FROM : $exp_dir" ### BB ###
            message "  TO : $exp_jobdir/bb"  ### Luster ###
            message ""

            message "[DWCLI] dwcli" "stage out" "--session $dwsessid" "--configuration $dwconfid" \
                "--backing-path $exp_jobdir/bb/" "--dir ${exp_dir:${#DW_JOB_STRIPED}}"
            dwcli stage out --session $dwsessid --configuration $dwconfid \
              --backing-path $exp_jobdir/bb/ --dir ${exp_dir:${#DW_JOB_STRIPED}}

            bb_stageoutwait

            message "-INFO- done"

            exp_dir=$exp_jobdir/bb
            plfs_dir=$exp_dir/plfs
            vpic_dir=$exp_dir/vpic
        fi

        ### READ PATH ###
        if [ $do_querying -eq 0 ]; then
            message ""
            message "!!! WARNING !!! write only - skipping read phase..."
            message ""
        else
            query_particles $runtype $exp_dir $pp
        fi
        ;;

    esac

    message ""
    message "--------------- [    OK    ] --------------"

    exp_logfile=""
}

#
# query_particles: query particle trajectories
#
# uses: $dfsu_prefix
#
# Arguments:
# @1 experiment type in {"baseline", "deltafs"}
# @2 vpic output directory
# @3 total number of particles
query_particles() {
    runtype=$1
    vpicout=$2
    pp=$3  ### for printing only ###

    case $runtype in
    "baseline")
        reader_bin="${dfsu_prefix}/bin/vpic-reader"
        reader_conf="-r 1 -n 1 -i $vpicout"
        nnum=$cores
        ;;
    "deltafs")
        reader_bin="${dfsu_prefix}/bin/simple-vpic-deltafs-reader"
        reader_conf="-r ${XX_RR_RANKS:-100} -d ${XX_RR_DEPTH:-1} -j ${XX_RR_BG:-4} -v $vpicout/plfs/particle $exp_jobdir/exp-info"
        nnum=1
        ;;
    *)
        die "query_particles: unknown runtype '$runtype'"
    esac

    if [ $nnum -le $nodes ]; then
        qppn=1
    else
        qppn=0
    fi

    message ""
    message "=================================================================="
    message "!!! Query VPIC ($runtype) with $pp particles on $nnum cores !!!"
    message "------------"
    message "> Using ${reader_bin}"
    message "> Experiment dir is ${vpicout}"
    message "> Log to ${exp_logfile}"
    message "  (+) Log to ${logfile}"
    message "      (+) Log to STDOUT"
    message "=================================================================="
    message ""

    # Query particles to see when the DeltaFS approach breaks compared to old,
    # single-pass approach. Otherwise query 100 particles to get a dependable
    # confidence interval.
    if [ $last -eq 1 ]; then
        do_mpirun $nnum $qppn "" $vpic_nodes "$reader_bin $reader_conf"
    else
        do_mpirun $nnum $qppn "" $vpic_nodes "$reader_bin $reader_conf"
    fi
}


#
# call common_init unless its been disabled (e.g. for debugging)
#
if [ x${common_noinit-} = x ]; then
    common_init
fi
